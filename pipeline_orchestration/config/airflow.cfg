[core]
executor = LocalExecutor  # Use LocalExecutor for parallel execution
dags_folder = /opt/airflow/dags  # DAGs directory inside the container
load_examples = False  # Disable default example DAGs for a cleaner UI
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres/airflow

[database]
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres/airflow
sql_engine_encoding = utf-8

[webserver]
web_server_port = 8080
base_url = http://localhost:8080
web_server_worker_timeout = 300  # Prevents webserver from failing under load

[logging]
base_log_folder = /opt/airflow/logs
executor_log_target = stdout  # Ensures logs are streamed properly in Docker

[scheduler]
dag_dir_list_interval = 30  # Check for new DAGs every 30 seconds
min_file_process_interval = 30
scheduler_heartbeat_sec = 10

[workers]
parallelism = 8  # Number of tasks Airflow can run in parallel
dag_concurrency = 4  # Max number of running DAGs at the same time

[api]
auth_backend = airflow.api.auth.backend.basic_auth  # Enable API authentication
